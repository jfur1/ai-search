{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Algorithms in Artificial Intelligence\n",
    "\n",
    "### Author: John Furlong\n",
    "\n",
    "#### Using examples from Artificial Intelligence: A Modern Approach (3rd Edition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from collections import deque\n",
    "import heapq\n",
    "import unittest\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**map_distances**          |  **map_times**\n",
    ":-------------------------:|:-------------------------:\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1j6Kam3F7ET-aIzT-6KMxaW7D7r8WAOME\" alt=\"Drawing\" style=\"width: 550px;\"/>  | <img src=\"http://drive.google.com/uc?export=view&id=1rI5w8CuWOS9reMIewc2IDBp_Z3pSUu1H\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' `previous` is a dictionary chaining together the predecessor state that led to each state. \n",
    "    `s` be None for the initial state. \n",
    "        - Otherwise, start from the last stae, and recursively trace back to the initial state.\n",
    "'''\n",
    "def path(previous, s):\n",
    "    if s is None:\n",
    "        return []\n",
    "    else:\n",
    "        return path(previous, previous[s]) + [s]\n",
    "\n",
    "'''Add up the step costs along a path, which is assumed to be the list output from the `path` function above.'''\n",
    "def pathcost(path, step_costs):\n",
    "    cost = 0\n",
    "    for s in range(len(path)-1):\n",
    "        cost += step_costs[path[s]][path[s+1]]\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all okay! (symmetric at least)\n",
      "all okay! (symmetric at least)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_distances = dict(\n",
    "    chi=dict(det=283, cle=345, ind=182),\n",
    "    cle=dict(chi=345, det=169, col=144, pit=134, buf=189),\n",
    "    ind=dict(chi=182, col=176),\n",
    "    col=dict(ind=176, cle=144, pit=185),\n",
    "    det=dict(chi=283, cle=169, buf=256),\n",
    "    buf=dict(det=256, cle=189, pit=215, syr=150),\n",
    "    pit=dict(col=185, cle=134, buf=215, phi=305, bal=247),\n",
    "    syr=dict(buf=150, phi=253, new=254, bos=312),\n",
    "    bal=dict(phi=101, pit=247),\n",
    "    phi=dict(pit=305, bal=101, syr=253, new=97),\n",
    "    new=dict(syr=254, phi=97, bos=215, pro=181),\n",
    "    pro=dict(bos=50, new=181),\n",
    "    bos=dict(pro=50, new=215, syr=312, por=107),\n",
    "    por=dict(bos=107))\n",
    "\n",
    "map_times = dict(\n",
    "    chi=dict(det=280, cle=345, ind=200),\n",
    "    cle=dict(chi=345, det=170, col=155, pit=145, buf=185),\n",
    "    ind=dict(chi=200, col=175),\n",
    "    col=dict(ind=175, cle=155, pit=185),\n",
    "    det=dict(chi=280, cle=170, buf=270),\n",
    "    buf=dict(det=270, cle=185, pit=215, syr=145),\n",
    "    pit=dict(col=185, cle=145, buf=215, phi=305, bal=255),\n",
    "    syr=dict(buf=145, phi=245, new=260, bos=290),\n",
    "    bal=dict(phi=145, pit=255),\n",
    "    phi=dict(pit=305, bal=145, syr=245, new=150),\n",
    "    new=dict(syr=260, phi=150, bos=270, pro=260),\n",
    "    pro=dict(bos=90, new=260),\n",
    "    bos=dict(pro=90, new=270, syr=290, por=120),\n",
    "    por=dict(bos=120))\n",
    "\n",
    "sld_providence = dict(\n",
    "    chi=833,\n",
    "    cle=531,\n",
    "    ind=782,\n",
    "    col=618,\n",
    "    det=596,\n",
    "    buf=385,\n",
    "    pit=458,\n",
    "    syr=253,\n",
    "    bal=325,\n",
    "    phi=236,\n",
    "    new=157,\n",
    "    pro=0,\n",
    "    bos=38,\n",
    "    por=136)\n",
    "\n",
    "def check_map(step_costs):\n",
    "    ''' function to check if all the path costs are at least symmetric '''\n",
    "    check_states = []\n",
    "    for state1 in step_costs.keys():\n",
    "        for state2 in step_costs[state1].keys():\n",
    "            uh_oh = step_costs[state2][state1]!=step_costs[state1][state2]\n",
    "            if uh_oh:\n",
    "                print('Check the costs between states {} and {}'.format(state1,state2))\n",
    "                check_states.append([state1,state2])\n",
    "    if len(check_states)==0:\n",
    "        print('all okay! (symmetric at least)')\n",
    "    return check_states\n",
    "\n",
    "# Verify symmetry of our step costs\n",
    "check_map(map_distances)\n",
    "check_map(map_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Uninformed Search Strategies\n",
    "\n",
    "## 1.a) Breadth First Search\n",
    "\n",
    "**breadth_first(start, goal, state_graph, return_cost)** searches the state space defined by **state_graph** using breadth first search\n",
    "\n",
    "* **start**: initial state (e.g., 'ind')\n",
    "* **end**: goal state (e.g., 'bos')\n",
    "* **state_graph**: the dictionary defining the step costs (e.g., `map_distances`)\n",
    "* **return_cost**: logical input representing whether or not to return the solution path cost\n",
    "  * If **True**, then the output should be a tuple where the first value is the list representing the solution path and the second value is the path cost\n",
    "  * If **False**, then the only output is the solution path list object\n",
    "  \n",
    "### Time Complexity: $O(b^d)$\n",
    "* The root of the search tree generates $b$ nodes at the first level, each of which generates $b$ more nodes, for a total of $b^2$ at the second level. Each of $\\textit{these}$ generates $b$ more nodes at the third level, and so on. \n",
    "* Now, suppose the solution is at depth $d$. In the worst case, this would be the last node generated at that level. Therefore, the total number of nodes generated would be:\n",
    "$$b + b^2 + b^3 + ... + b^d = O(b^d)$$\n",
    "\n",
    "### Space Complexity: $O(b^d)$\n",
    "* For any kind of graph search that stores ecert expanded node in an `explored` set, the space complexity is always within a factor $b$ of the time complexity.\n",
    "* There will be $O(b^{d-1})$ nodes in the `explored` set, and $O(b^d)$ nodes in the frontier. Therefore, space complexity is also $O(b^d)$\n",
    "\n",
    "### Notes:\n",
    "* The memory requirements are a bigger problem for breadth-first search than is the execution time.\n",
    "* In general, exponential-complexity search problems cannot be solved by uninformed search methods for any but the smallest instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breadth_first(start, end, state_graph, return_cost):\n",
    "    \n",
    "    # Frontier Queue\n",
    "    frontier = [start]\n",
    "    explored = []\n",
    "    \n",
    "    prev = dict()\n",
    "    prev[start] = None\n",
    "    \n",
    "    while frontier:\n",
    "        # FIFO Queue\n",
    "        state = frontier.pop(0)\n",
    "        explored.append(state)\n",
    "\n",
    "        for child in state_graph[state].keys():\n",
    "\n",
    "            if child not in explored and child not in frontier:\n",
    "\n",
    "                frontier.append(child)\n",
    "                prev[child] = state\n",
    "\n",
    "                if(child == end):\n",
    "\n",
    "                    Path = path(prev, end)\n",
    "\n",
    "                    if(return_cost):\n",
    "                        return(Path, pathcost(Path, state_graph))\n",
    "                    else:\n",
    "                        return Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b) Depth First Search (for Graphs)\n",
    "\n",
    "**depth_first(start, end, state_graph, return_cost)** searches the state space defined by **state_graph** using depth-first search:\n",
    "* **start**: initial state (e.g., 'ind')\n",
    "* **end**: goal state (e.g., 'bos')\n",
    "* **state_graph**: the dictionary defining the step costs (e.g., `map_distances`)\n",
    "* **return_cost**: logical input representing whether or not to return the solution path cost\n",
    "    * If **True**, then the output should be a tuple where the first value is the list representing the solution path and the second value is the path cost\n",
    "    * If **False**, then the only output is the solution path list object\n",
    "\n",
    "### Time Complexity: $O(V + E)$\n",
    "* Where $V$ is the number of vertices, and $E$ is the number of edges.\n",
    "* Time complexity of DFS is bounded by the size of the state space (which may be infinite). In our Graph-DFS implementation the state space is finite.\n",
    "\n",
    "### Space Complexity: $O(V)$\n",
    "* Where $V$ is the size of the visited array.\n",
    "\n",
    "#### Notes:\n",
    "* Remember that this is a depth-first search implementation for $\\textbf{graphs}$. The implementation for trees works a bit differently, and also has different time/space complexities.\n",
    "* Graph-DFS is **complete** (in finite state spaces), unlike Tree-DFS which is incomplete and may get stuck in an infinite loop.\n",
    "* Graph-DFS is not **optimal**, since the algorithm chooses the next deepest node for expansion, and not necessarily the optimal node.\n",
    "* Possible Optimizations:\n",
    "    - Depth-limited Search: Limit the number of iterations to avoid infinite loops\n",
    "    - Iterative Deepening Depth-First Search: Find the optimal depth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS(state, end, state_graph, explored, prev):\n",
    "    \n",
    "    if state in explored:\n",
    "        return False\n",
    "\n",
    "    explored.append(state)\n",
    "    \n",
    "    if(state == end):\n",
    "        return True\n",
    "\n",
    "    # Recur for all adjacent cities\n",
    "    for child in state_graph[state].keys():\n",
    "        # Check if child has been explored to avoid loops\n",
    "        if child in explored:\n",
    "            continue\n",
    "        prev[child] = state\n",
    "        if(DFS(child, end, state_graph, explored, prev)):\n",
    "            return prev\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_first(start, end, state_graph, return_cost):\n",
    "    explored = []\n",
    "    prev = dict()\n",
    "    prev[start] = None\n",
    "\n",
    "    result = DFS(start, end, state_graph, explored, prev)\n",
    "    if(result != False):\n",
    "        Path = path(result, end)\n",
    "        if return_cost:\n",
    "            return (Path, pathcost(Path, state_graph))\n",
    "        else:\n",
    "            return Path\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c) Uniform-Cost Search\n",
    "\n",
    "First, we must create a `Frontier_PQ` class to represent the frontier (priority queue) for uniform-cost search.\n",
    "* Instantiation arguments: \n",
    "  * **Frontier_PQ(start, cost)**\n",
    "  * **start** is the initial state (e.g., **start**='chi')\n",
    "  * **cost** is the initial path cost (what should it be for the initial state?)\n",
    "* Instantiation attributes/methods:\n",
    "  * **states**: maintains a dictionary of states on the frontier, along with the _minimum_ path cost to arrive at them\n",
    "  * **q**: a list of (cost, state) tuples, representing the elements on the frontier; should be treated as a priority queue (in contrast to the **states** dictionary, which is meant to keep track of the lowest-cost to each state)\n",
    "  * appropriately initialize the starting state and cost\n",
    "* Methods to implement:\n",
    "  * **add(state, cost)**: add the (cost, state) tuple to the frontier\n",
    "  * **pop()**: return the lowest-cost (cost, state) tuple, and pop it off the frontier\n",
    "  * **replace(state, cost)**: if you find a lower-cost path to a state that's already on the frontier, it should be replaced using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frontier_PQ:\n",
    "    \n",
    "    def __init__(self, start, cost):\n",
    "        self.states = dict()\n",
    "        self.states[start] = 0\n",
    "        self.q = [(0, start)]\n",
    "        \n",
    "    def add(self, state, cost):\n",
    "        self.q.append((cost, state))\n",
    "        \n",
    "    def pop(self):\n",
    "        min_cost = 10000\n",
    "        min_loc = None\n",
    "        for cost, state in self.q:\n",
    "            if(cost < min_cost):\n",
    "                min_loc = state\n",
    "                min_cost = cost\n",
    "        # Return lowest (cost, location) tuple and remove it from the frontier\n",
    "        self.q.remove((min_cost, min_loc))\n",
    "        return min_cost, min_loc \n",
    "\n",
    "    def replace(self, state, cost):\n",
    "        for i, j in self.q:\n",
    "            if(j == state):\n",
    "                self.q.remove((i, j))\n",
    "                self.q.append((cost, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can actually implement a function to search using `uniform_cost` search, called as **uniform_cost(start, goal, state_graph, return_cost)**:\n",
    "* **start**: initial state\n",
    "* **goal**: goal state\n",
    "* **state_graph**: graph representing the connectivity and step costs of the state space (e.g., **map_distances** or **map_times** below)\n",
    "* **return_cost**: logical input representing whether or not to return the solution path cost\n",
    "  * If **True**, then the output should be a tuple where the first value is the list representing the solution path and the second value is the path cost\n",
    "  * If **False**, then the only output is the solution path list object\n",
    "  \n",
    "### Time Complexity: $O(b^{1 + C^*/e})$\n",
    "* If the branching factor is `b` each time you expand a node, you will encounter `k` more nodes. Therefore, if your goal node is in layer `k`, you will have to expand $O(b^k)$ nodes to find your target.\n",
    "* If C* is the cost of your optimal solution, and each action costs at least $\\varepsilon$, then the algorithm's worst case time & space complexity is $O(b^{1 + C^*/e})$\n",
    "\n",
    "### Space Complexity: $O(b^{1 + C^*/e})$\n",
    "* Note: If all step costs are equal, then $O(b^{1 + C^*/e}) = O(b^{d+1})$\n",
    "\n",
    "### Notes:\n",
    "* Uniform-Cost Search is **optimal** with any step cost function!\n",
    "    - Instead of expanding the shallowest/deepest node, we expand the node $n$ with the lowest path cost $g(n)$.\n",
    "    - This is done by storing the frontier as a priority queue, ordered by $g$\n",
    "* UCS does not care about the $textit{number}$ of steps a path has, but only about their total cost.\n",
    "    - Therefore, UCS gets stuck in an infinite loop if there is a path with an infinite sequence of zerp-cost actions.\n",
    "    - In general, the uniform-cost serach is **complete**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_cost(start, end, state_graph, return_cost):\n",
    "    \n",
    "    frontier = Frontier_PQ(start, 0)\n",
    "    \n",
    "    explored = []\n",
    "    prev = dict()\n",
    "    prev[start] = None\n",
    "    \n",
    "    while frontier:\n",
    "        # Pops the lowest cost tuple off the PQ -- guarenteed shortest path to this location\n",
    "        cost, state = frontier.pop()\n",
    "        explored.append(state)\n",
    "        \n",
    "        # Perform goal test after we expand on a node\n",
    "        if state == end:\n",
    "            Path = path(prev, end)\n",
    "            if(return_cost):\n",
    "                return (Path, pathcost(Path, state_graph))\n",
    "            else:\n",
    "                return Path\n",
    "        \n",
    "        # Add every adjacent node\n",
    "        for child in state_graph[state].keys():\n",
    "            child_cost = cost + state_graph[state][child]\n",
    "            \n",
    "            if child not in frontier.states.keys() and child not in explored:\n",
    "                frontier.add(child, child_cost)\n",
    "                prev[child] = state\n",
    "            elif child in frontier.states.keys() and child_cost < frontier.states[child]:\n",
    "                frontier.replace(child, child_cost)\n",
    "                prev[child] = state\n",
    "            frontier.states[child] = child_cost\n",
    "            \n",
    "    return 'No path found'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d) Testing\n",
    "\n",
    "### State Space: Map Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Space: Map Distances\n",
      "Result from breadth-first search:  (['chi', 'det', 'buf', 'syr', 'new'], 943)\n",
      "Result from depth-first search:  (['chi', 'det', 'cle', 'col', 'pit', 'buf', 'syr', 'phi', 'new'], 1496)\n",
      "Result from uniform-cost search:  (['chi', 'cle', 'pit', 'bal', 'phi', 'new'], 924)\n"
     ]
    }
   ],
   "source": [
    "bfs = breadth_first('chi', 'new', map_distances, return_cost = True)\n",
    "dfs = depth_first('chi', 'new', map_distances, return_cost = True)\n",
    "ucs = uniform_cost('chi', 'new', map_distances, return_cost = True)\n",
    "\n",
    "print('State Space: Map Distances')\n",
    "print('Result from breadth-first search: ', bfs)\n",
    "print('Result from depth-first search: ', dfs)\n",
    "print('Result from uniform-cost search: ', ucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here, we can see that uniform-cost search returned the shortest path. We also know from the behavior of uniform-cost search, that this is also the optimal path. Another interesting feature of uniform-cost search is that the algorithm does not care about the $\\textit{number}$ of steps a path has, but only their total cost (miles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Space: Map Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Space: Map Times\n",
      "Result from breadth-first search:  (['chi', 'det', 'buf', 'syr', 'new'], 955)\n",
      "Result from depth-first search:  (['chi', 'det', 'cle', 'col', 'pit', 'buf', 'syr', 'phi', 'new'], 1545)\n",
      "Result from uniform-cost search:  (['chi', 'cle', 'buf', 'syr', 'new'], 935)\n"
     ]
    }
   ],
   "source": [
    "bfs = breadth_first('chi', 'new', map_times, return_cost = True)\n",
    "dfs = depth_first('chi', 'new', map_times, return_cost = True)\n",
    "ucs = uniform_cost('chi', 'new', map_times, return_cost = True)\n",
    "\n",
    "print('State Space: Map Times')\n",
    "print('Result from breadth-first search: ', bfs)\n",
    "print('Result from depth-first search: ', dfs)\n",
    "print('Result from uniform-cost search: ', ucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see that uniform-cost search again returned the optimal path. The key here is that uniform-cost search expands nodes in order of thier optimal path cost. Another important thing to notice is that DFS & BFS return the same paths, regardless of which state space is used, while uniform-cost search returns a different path based on the optimal path cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.) Solving a Maze\n",
    "\n",
    "Consider this maze, where gray tiles represent walls and orange tiles represent open space where you can walk.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1bCT7aePAwB1t8ZdIboOqmhzMAQ_grKBZ\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "We can represent this maze using a binary `numpy` array as follows, where 1s represent walls and 0s represent open space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                 [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                 [1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
    "                 [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                 [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
    "                 [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
    "                 [1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1],\n",
    "                 [1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1],\n",
    "                 [1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
    "                 [1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1],\n",
    "                 [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
    "                 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** the *first* row of the **maze** array corresponds to the *bottom* row of tiles in the figure.  This is a choice made  to reflect the fact that we are going to search for a solution path through this maze in *physical* space, so it is useful for our coordinate system to match Cartesian coordinates. This is in contrast to using the first row of the **maze** array to represent the top of the maze, which looks intuitive.\n",
    "\n",
    "## 2.a) Converting Grid to Graph\n",
    "\n",
    "Function **maze_to_graph(maze)**:\n",
    "* Takes as input a binary maze **maze**, stored as a `numpy` array, where 0 represents an open path and 1 represents a wall\n",
    "* returns a graph dictionary in a similar style to **map_distances** and **map_times**\n",
    "  * the keys are tuples giving the states (coordinate pairs) within the maze (e.g., (1,1) represents the lower-left open space, (2,1) represents the space **to the right** of (1,1), and (0,0) represents the lower-left corner, a wall location); thus, the coordinates within the maze are like Cartesian coordinates, and the x- and y-axes are the bottom and left walls of the maze, respectively\n",
    "  * the values are themselves dictionaries, where the keys are other states within the maze and the values are the actions taken to move to that state\n",
    "  * the actions are moves from the list ['N','S','E','W']\n",
    "  * i.e., dict[(x, y)] = direction_to_arrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maze_to_graph(maze):\n",
    "    graph = dict()\n",
    "    \n",
    "    for i in range(1, len(maze)-1):\n",
    "        \n",
    "        for j in range(1, len(maze[i])-1):\n",
    "            \n",
    "            tmp_adj = dict()\n",
    "            \n",
    "            if maze[i, j] == 1:\n",
    "                graph[(j, i)] = tmp_adj\n",
    "                continue\n",
    "                    \n",
    "            if maze[i-1, j] == 0:\n",
    "                tmp_adj[(j, i-1)] = 'S'\n",
    "                \n",
    "            if maze[i, j-1] == 0:\n",
    "                tmp_adj[(j-1, i)] = 'W'\n",
    "                \n",
    "            if maze[i+1, j] == 0:\n",
    "                tmp_adj[(j, i+1)] = 'N'\n",
    "                \n",
    "            if maze[i, j+1] == 0:\n",
    "                tmp_adj[(j+1, i)] = 'E'\n",
    "\n",
    "            graph[(j, i)] = tmp_adj\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b) Solving the Maze-Graph\n",
    "\n",
    "We can now use our **maze_to_graph** function to convert the 2D array-representation of the maze into a graph-maze implementation. With our maze represented as a graph, we are able to solve it using our search algorithms:\n",
    "- Let the initial state be: (1,1)\n",
    "- Let the goal state be (10, 10)\n",
    "\n",
    "We will use **breadth-first search** and **depth-first search** to solve the maze, starting from the bottom left, and ending in the top right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_maze = depth_first((1,1), (10,10), maze_graph, return_cost = False)\n",
    "bfs_maze = breadth_first((1,1), (10,10), maze_graph, return_cost = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-First Search:\n",
      " path: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (2, 10), (3, 10), (3, 9), (4, 9), (4, 8), (4, 7), (3, 7), (3, 6), (3, 5), (3, 4), (3, 3), (4, 3), (5, 3), (6, 3), (7, 3), (8, 3), (9, 3), (10, 3), (10, 4), (10, 5), (9, 5), (8, 5), (7, 5), (6, 5), (6, 6), (6, 7), (6, 8), (7, 8), (8, 8), (9, 8), (10, 8), (10, 9), (10, 10)]\n",
      "Length: 43\n",
      "\n",
      "Breadth-First Search:\n",
      " [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 6), (3, 6), (3, 7), (4, 7), (5, 7), (6, 7), (6, 8), (7, 8), (8, 8), (9, 8), (10, 8), (10, 9), (10, 10)]\n",
      "Length: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"Depth-First Search:\\n\", \"path:\", dfs_maze)\n",
    "print(\"Length:\", len(dfs_maze))\n",
    "print(\"\\nBreadth-First Search:\\n\", bfs_maze)\n",
    "print(\"Length:\", len(bfs_maze))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.c) Plotting the Maze\n",
    "Now, we will write a function **plot_maze(maze, path)** that takes as input a binary `numpy` array **maze** (1s represent walls, 0s represent open space) and a solution **path**, and plots the two together.\n",
    "* **maze**: a maze represented as a binary `numpy` array, as above\n",
    "* **path**: a solution path found using search algorithms above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_maze(maze, path = None):\n",
    "    x_coords, y_coords = [], []\n",
    "    \n",
    "    for i in range(0, len(path)):\n",
    "        x = path[i][1]\n",
    "        y = path[i][0]\n",
    "        x_coords.append(x)\n",
    "        y_coords.append(y)\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize = (7, 7))\n",
    "    path_len = len(path)-1\n",
    "    \n",
    "    x_start, y_start = path[0][0], path[0][1]\n",
    "    x_goal, y_goal = path[path_len][0], path[path_len][1]\n",
    "    \n",
    "    ax.scatter(x_start , y_start, marker = \"*\", color = \"red\", s = 200)\n",
    "    ax.scatter(x_goal , y_goal, marker = \"*\", color = \"yellow\", s = 200)\n",
    "    ax.imshow(maze, cmap= plt.cm.Dark2, origin='lower')\n",
    "    ax.plot(y_coords,x_coords, color = \"black\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-First Search Solution\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breadth-First Search Solution\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Depth-First Search Solution:\")\n",
    "plot_maze(maze, dfs_maze)\n",
    "print(\"Breadth-First Search Solution:\")\n",
    "plot_maze(maze, bfs_maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.) Heuristics and Informed Search Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Informed search strategies** use problem-specific knowledge beyond the definition of the problem itself.\n",
    "\n",
    "Now, we will be using an informed algorithm known as Astar Search. What makes the algorithm \"informed\" in this case, is the dictionary `sld_providence`, which is the straight-line distance from major cities to Providence. This is called a heuristic function, and we will see later that there are different kinds of heuristic functions. Also note that because it doesn't make much sense to add estimated travel times and the straight-line distance, we will only be using the `map_distances` state space graph for this problem.\n",
    "\n",
    "**map_distances**          |  **sld_providence**\n",
    ":-------------------------:|:-------------------------:\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1j6Kam3F7ET-aIzT-6KMxaW7D7r8WAOME\" alt=\"Drawing\" style=\"width: 500px;\"/>  | <img src=\"http://drive.google.com/uc?export=view&id=1a8FNEG7apKkRX7VvpdMgmeYbqeNuOdwz\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a) Modifying Our Uniform Cost Search\n",
    "\n",
    "We will include a parameter which will indicate whether or not to return the number of states expanded during the search. Here, we are not yet using a heuristic function, but preparing to compare uniform-cost search to astar search. More specifically, we will include a new optional boolean (T/F) argument **return_nexp** which, when true, also returns the number of nodes expanded on by the algorithm. Similarly, the argument **return_cost** returns the total path cost when true.\n",
    "\n",
    "Function: `uniform_cost(start, goal, state_graph, return_cost, return_nexp)`:\n",
    "* If `return_nexp` is True, then the last output in the output tuple should be the number of nodes expanded.\n",
    "* If `return_nexp` is False, then the code should behave exactly as it did in Homework 2.\n",
    "\n",
    "Then, we will verify that our revised code is working by recomputing the optimal route from Chicago to New York. Include the number of nodes expanded and the path cost (using `map_distances`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_cost(start, goal, state_graph, return_cost, return_nexp):\n",
    "    \n",
    "    frontier = Frontier_PQ(start, 0)\n",
    "    \n",
    "    explored = []\n",
    "    prev = dict()\n",
    "    prev[start] = None\n",
    "    explored_count = 0\n",
    "    \n",
    "    while frontier:\n",
    "        # Pops the lowest cost tuple off the PQ -- guarenteed shortest path to this location\n",
    "        cost, state = frontier.pop()\n",
    "        \n",
    "        # Perform goal test after we expand on a node\n",
    "        if state == goal:\n",
    "            Path = path(prev, goal)\n",
    "            if(return_cost and return_nexp):\n",
    "                return (Path, pathcost(Path, state_graph), len(explored))\n",
    "            elif(return_cost and not return_nexp):\n",
    "                return (Path, pathcost(Path, state_graph))\n",
    "            elif(not return_cost and return_nexp):\n",
    "                return (Path, len(explored))\n",
    "            else:\n",
    "                return Path\n",
    "        \n",
    "        explored.append(state)\n",
    "        \n",
    "        # Add every adjacent node\n",
    "        for child in state_graph[state].keys():\n",
    "            child_cost = cost + state_graph[state][child]\n",
    "            \n",
    "            if child not in frontier.states.keys() and child not in explored:\n",
    "                frontier.add(child, child_cost)\n",
    "                prev[child] = state\n",
    "            elif child in frontier.states.keys() and child_cost < frontier.states[child]:\n",
    "                frontier.replace(child, child_cost)\n",
    "                prev[child] = state\n",
    "            frontier.states[child] = child_cost\n",
    "            \n",
    "    return 'No path found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Uniform Cost Search ******\n",
      "Optimal Path: ['chi', 'cle', 'pit', 'bal', 'phi', 'new']\n",
      "Optimal Path Cost: 924\n",
      "Number of States Expanded: 10\n"
     ]
    }
   ],
   "source": [
    "ucs_path, ucs_cost, ucs_nexp = uniform_cost('chi', 'new', map_distances, return_cost = True, return_nexp = True)\n",
    "print(\"****** Uniform Cost Search ******\")\n",
    "print(\"Optimal Path:\", ucs_path)\n",
    "print(\"Optimal Path Cost:\", ucs_cost)\n",
    "print(\"Number of States Expanded:\", ucs_nexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b) Heuristic Function\n",
    "\n",
    "We will now define a function to take as an argument `state` and return the value of the straight-line distance heuristic between `state` and Providence. The value will be found using the `sld_providence` dictionary at the start of the notebook. We will call the function `heuristic_sld_providence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_sld_providence(state):\n",
    "    return sld_providence[state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "833"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heuristic_sld_providence('chi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Admissibility & Consistency**\n",
    "\n",
    "**Admissible Heuristics**: never $\\textit{overestimate}$ the cost to reach the goal\n",
    "* Straight-line distance is an example of an admissible heuristic, since the shortest path between any two points is a line, and the straight line cannot be an overestimate.\n",
    "\n",
    "**Consistent Heuristics**: For ever node `n` and every successor `n'` of `n` generated by an action `a`, the estimated cost of reaching the goal from `n` is no greater than the cost of getting to `n'` plus the estimated cost of reaching the goal from `n'`.\n",
    "* This is a form of the general triangle inequality: $h(n) \\leq c(n, a, n') + h(n')$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.c) A* Search (for Graphs)\n",
    "\n",
    "We can now perform a complete **A* Search** using as a heuristic function the straight-line distance to Providence. To do so, we will add an additional argument `heuristic`, so our function will look like the following: `astar_search(start, goal, state_graph, heuristic, return_cost, return_nexp)`. (This type of modular programming makes it easier to use alternative heuristic functions later).\n",
    "\n",
    "### Time Complexity $O(b^d)$: \n",
    "* Depends on the heuristic, but in the absolute worst-case: $O(b^d)$\n",
    "    - Where $b$ is the branching factor and $d$ is the depth\n",
    "* The heuristic significantly improves performance by allowing A* to prune away many of the $b^d$ nodes that an uninformed search would expand. We can see this by solving the number of nodes expanded, $N$:\n",
    "$$N + 1 = 1 + b^* + (b^*)^2 + ... + (b^*)^d$$\n",
    "* Good heuristics are those with low effective branching factor (the optimal being $b^* = 1$.\n",
    "\n",
    "### Space Complexity: $O(V)$\n",
    "* Where $V$ is the number of vertices.\n",
    "* In the worst-case, the optimal path visits every vertex and stores every node in memory. \n",
    "\n",
    "### Notes:\n",
    "* **Consitent and Optimal*** (*Depending on the admissibility/consistency of the heuristic, as well as tree/graph implementation\n",
    "* **Optimally Efficient**: No other optimal algorithm is guarenteed to expand fewer nodes than A*\n",
    "* A* Search is identical to uniform-cost search except that A* uses $g + h$ instead of just $g$\n",
    "* The tree-search version of A* is optimal if h(n) is admissible, while the garph-search version is optimal if h(n) is consistent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_search(start, goal, state_graph, heuristic, return_cost, return_nexp):\n",
    "    \n",
    "    frontier = Frontier_PQ(start, 0)\n",
    "    \n",
    "    explored = []\n",
    "    prev = dict()\n",
    "    prev[start] = None\n",
    "    explored_count = 0\n",
    "    \n",
    "    while frontier:\n",
    "        # Pops the lowest cost tuple off the PQ -- guarenteed shortest path to this location\n",
    "        cost, state = frontier.pop()\n",
    "        \n",
    "        # Perform goal test after we expand on a node\n",
    "        if state == goal:\n",
    "            Path = path(prev, goal)\n",
    "            if(return_cost and return_nexp):\n",
    "                return (Path, pathcost(Path, state_graph), len(explored))\n",
    "            elif(return_cost and not return_nexp):\n",
    "                return (Path, pathcost(Path, state_graph))\n",
    "            elif(not return_cost and return_nexp):\n",
    "                return (Path, len(explored))\n",
    "            else:\n",
    "                return Path\n",
    "        \n",
    "        explored.append(state)\n",
    "        \n",
    "        # Add every adjacent node\n",
    "        for child in state_graph[state].keys():\n",
    "            g = cost + state_graph[state][child]\n",
    "            h = heuristic(child)\n",
    "            f = g + h\n",
    "            \n",
    "            if child not in frontier.q and child not in explored:\n",
    "                frontier.add(child, f)\n",
    "                prev[child] = state\n",
    "            elif child in frontier.q and f < frontier.states[child]:\n",
    "                frontier.replace(child, f)\n",
    "                prev[child] = state\n",
    "            frontier.states[child] = f\n",
    "            \n",
    "    return 'No path found'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.d) Comparing Uniform-Cost Search & A* Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** A* Search ***********\n",
      "Optimal Path: ['buf', 'syr', 'bos', 'pro']\n",
      "Optimal Path Cost: 512\n",
      "Number of States Expanded: 5 \n",
      "\n",
      "****** Uniform Cost Search ******\n",
      "Optimal Path: ['buf', 'syr', 'bos', 'pro']\n",
      "Optimal Path Cost: 512\n",
      "Number of States Expanded: 11\n"
     ]
    }
   ],
   "source": [
    "astar_path, astar_cost, astar_nexp = astar_search('buf', 'pro', map_distances, heuristic_sld_providence, return_cost = True, return_nexp = True)\n",
    "ucs_path, ucs_cost, ucs_nexp = uniform_cost('buf', 'pro', map_distances, return_cost = True, return_nexp = True)\n",
    "\n",
    "print(\"*********** A* Search ***********\")\n",
    "print(\"Optimal Path:\", astar_path)\n",
    "print(\"Optimal Path Cost:\", astar_cost)\n",
    "print(\"Number of States Expanded:\", astar_nexp, '\\n')\n",
    "print(\"****** Uniform Cost Search ******\")\n",
    "print(\"Optimal Path:\", ucs_path)\n",
    "print(\"Optimal Path Cost:\", ucs_cost)\n",
    "print(\"Number of States Expanded:\", ucs_nexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter what the `start` and `goal` states are, there will never be an algorithm that is guarenteed to expand less nodes than A* Search, which is why we can see it expanded less than half as many nodes as uniform-cost search. Both algorithms are **optimal** and **complete**; however, including a consistent heuristic for our graph allows it to return the optimal path while expanding on the fewest nodes possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
